---
phase: 02-unit-test-coverage
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/COVERAGE.md
  - .planning/REQUIREMENTS.md
autonomous: true

must_haves:
  truths:
    - "Developer can read COVERAGE.md to understand which modules are tested vs untested"
    - "Each untested module has documented rationale for deferred testing"
    - "Document identifies high-priority vs low-priority testing gaps"
  artifacts:
    - path: ".planning/COVERAGE.md"
      provides: "Coverage gaps analysis and rationale"
      min_lines: 100
  key_links:
    - from: ".planning/COVERAGE.md"
      to: "packages/shared/src/**"
      via: "module inventory references"
      pattern: "packages/shared"
---

<objective>
Document coverage gaps with analysis of tested vs untested modules and rationale for deferred tests.

Purpose: The codebase has ~46% function coverage and ~51% line coverage. Rather than blindly adding tests, we document which modules need tests, which are low-priority, and why. This creates a testing roadmap and prevents coverage theater.

Output: .planning/COVERAGE.md with module-by-module analysis. Requirement COV-03 complete.
</objective>

<execution_context>
<!-- Executor agent has built-in instructions for plan execution and summary creation -->
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/pending/02-unit-test-coverage/02-RESEARCH.md
@packages/shared/src/git/__tests__/git-service.test.ts
@packages/shared/src/git/__tests__/pr-service.test.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Analyze coverage and create COVERAGE.md</name>
  <files>.planning/COVERAGE.md</files>
  <action>
Run `bun run test:coverage 2>&1` and analyze the output to create `.planning/COVERAGE.md` with this structure:

```markdown
# Test Coverage Analysis

**Last updated:** {current date}
**Overall coverage:** {from report}

## Coverage Summary

| Area | Functions | Lines | Status |
|------|-----------|-------|--------|
| packages/shared | X% | X% | {status} |
| packages/mermaid | X% | X% | {status} |
| apps/electron/src | X% | X% | {status} |

## Well-Tested Modules (>80% coverage)

List modules with good coverage:
- `packages/shared/src/git/` - git-service.ts, pr-service.ts (comprehensive tests)
- `packages/shared/src/agent/tool-matching.ts` - determinism tests
- `packages/mermaid/` - parser, renderer tests

## Coverage Gaps

### High Priority (business logic, should have tests)

For each module with <50% coverage that contains business logic:
- Module path
- Current coverage
- What it does
- Why it needs tests (risk assessment)
- Recommended test approach

Candidates (from coverage report analysis):
- `packages/shared/src/agent/mode-manager.ts` - 32.5% functions, permission mode state machine
- `packages/shared/src/config/storage.ts` - 0% functions, config persistence
- `packages/shared/src/sessions/storage.ts` - 0% functions, session persistence

### Low Priority (deferred with rationale)

For each module where testing is deferred:
- Module path
- Rationale (one of: integration-test territory, simple glue code, external dependency heavy, UI-layer)

Candidates:
- `packages/shared/src/auth/*.ts` - OAuth flows require real credentials, tested via E2E
- `packages/shared/src/sources/*.ts` - MCP integration, needs mock servers
- `packages/shared/src/credentials/*.ts` - OS keychain integration, platform-specific

### Out of Scope

- `apps/electron/src/main/` - Electron main process, tested via E2E
- `apps/electron/src/renderer/` - React components, tested via E2E

## Testing Recommendations

Prioritized list of modules to add tests to in future:
1. {module} - {why important}
2. {module} - {why important}
3. ...

## Notes

- Coverage threshold not enforced (warning-only policy)
- Goal is not 100% coverage but appropriate coverage
- E2E tests cover integration paths that unit tests cannot
```

Analyze the coverage output carefully. Categorize each major module (not individual files) into:
1. Well-tested (keep as-is)
2. High priority gap (business logic, state machines, persistence)
3. Low priority (defer with rationale)
4. Out of scope (tested via E2E)
  </action>
  <verify>
Read .planning/COVERAGE.md and verify:
1. Contains current coverage numbers from report
2. Lists at least 3 well-tested modules
3. Lists at least 3 high-priority gaps with rationale
4. Lists at least 3 low-priority deferred modules with rationale
5. Has recommendations section
  </verify>
  <done>COVERAGE.md exists with comprehensive analysis of tested vs untested modules and clear rationale for each category</done>
</task>

<task type="auto">
  <name>Task 2: Mark COV-03 complete and update progress</name>
  <files>.planning/REQUIREMENTS.md</files>
  <action>
In .planning/REQUIREMENTS.md:

1. Update COV-03 status:
```markdown
- [x] **COV-03**: Other coverage gaps identified by report are filled or documented with rationale
```

2. Update Traceability table to add:
| COV-03 | Phase 2 | 02-02 | Complete |

3. Verify all COV-* requirements are now [x] marked.
  </action>
  <verify>Read .planning/REQUIREMENTS.md and confirm COV-03 is marked [x] and traceability table is complete</verify>
  <done>All COV requirements complete, traceability table updated</done>
</task>

</tasks>

<verification>
1. .planning/COVERAGE.md exists and is >100 lines
2. Document has clear structure with Summary, Well-Tested, Gaps (High/Low Priority), Out of Scope sections
3. Each gap has documented rationale
4. COV-03 marked complete in REQUIREMENTS.md
</verification>

<success_criteria>
1. COVERAGE.md provides actionable testing roadmap
2. Rationale for deferred tests is documented (not just "TODO")
3. High-priority vs low-priority distinction is clear
4. All COV requirements complete
</success_criteria>

<output>
After completion, create `.planning/phases/pending/02-unit-test-coverage/02-02-SUMMARY.md`
</output>
